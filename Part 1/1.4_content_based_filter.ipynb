{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_F1tARinHUW",
        "outputId": "6c10d5b9-1e49-4ee2-db80-93aac150b710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  955k  100  955k    0     0  1805k      0 --:--:-- --:--:-- --:--:-- 1802k\n"
          ]
        }
      ],
      "source": [
        "! curl http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR8QnDXvnSW7"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzo4QkvunT-C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "movies_df = pd.read_csv('data/ml-latest-small/movies.csv')\n",
        "ratings_df = pd.read_csv('data/ml-latest-small/ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v574BcWnVQT",
        "outputId": "53b1f0f6-b17b-4f82-efd5-783970721da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dimensions of movies dataframe are: (9742, 3) \n",
            "The dimensions of ratings dataframe are: (100836, 4)\n"
          ]
        }
      ],
      "source": [
        "print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNEQpMYznX-z",
        "outputId": "44fdeeb8-d316-4173-b1a8-bd2b00e8f60d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique users: 610\n",
            "Number of unique movies: 9724\n",
            "The full rating matrix will have: 5931640 elements.\n",
            "----------\n",
            "Number of ratings: 100836\n",
            "Therefore:  1.6999683055613624 % of the matrix is filled.\n",
            "We have an incredibly sparse matrix to work with here.\n",
            "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
            "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
            "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Movie ID to movie name mapping\n",
        "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
        "n_users = len(ratings_df.userId.unique())\n",
        "n_items = len(ratings_df.movieId.unique())\n",
        "print(\"Number of unique users:\", n_users)\n",
        "print(\"Number of unique movies:\", n_items)\n",
        "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
        "print('----------')\n",
        "print(\"Number of ratings:\", len(ratings_df))\n",
        "print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
        "print(\"We have an incredibly sparse matrix to work with here.\")\n",
        "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
        "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
        "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7_lxzgInaRq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "class MatrixFactorization(torch.nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=20):\n",
        "        super().__init__()\n",
        "        # create user embeddings\n",
        "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
        "        # create item embeddings\n",
        "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
        "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
        "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        # matrix multiplication\n",
        "        users, items = data[:,0], data[:,1]\n",
        "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
        "    # def forward(self, user, item):\n",
        "    # \t# matrix multiplication\n",
        "    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
        "    \n",
        "    def predict(self, user, item):\n",
        "        return self.forward(user, item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jquRJkooncIJ"
      },
      "outputs": [],
      "source": [
        "# Creating the dataloader (necessary for PyTorch)\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
        "\n",
        "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
        "class Loader(Dataset):\n",
        "    def __init__(self):\n",
        "        self.ratings = ratings_df.copy()\n",
        "        \n",
        "        # Extract all user IDs and movie IDs\n",
        "        users = ratings_df.userId.unique()\n",
        "        movies = ratings_df.movieId.unique()\n",
        "        \n",
        "        #--- Producing new continuous IDs for users and movies ---\n",
        "        \n",
        "        # Unique values : index\n",
        "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
        "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
        "        \n",
        "        # Obtained continuous ID for users and movies\n",
        "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
        "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
        "        \n",
        "        # return the id from the indexed values as noted in the lambda function down below.\n",
        "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
        "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
        "        \n",
        "        \n",
        "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
        "        self.y = self.ratings['rating'].values\n",
        "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkGDHkVGndfT",
        "outputId": "ba56ebc3-fc5b-4a81-fe81-6c8e1998ac4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is running on GPU: False\n",
            "MatrixFactorization(\n",
            "  (user_factors): Embedding(610, 8)\n",
            "  (item_factors): Embedding(9724, 8)\n",
            ")\n",
            "user_factors.weight tensor([[0.0281, 0.0224, 0.0136,  ..., 0.0346, 0.0447, 0.0223],\n",
            "        [0.0025, 0.0376, 0.0024,  ..., 0.0321, 0.0203, 0.0120],\n",
            "        [0.0359, 0.0456, 0.0129,  ..., 0.0419, 0.0420, 0.0133],\n",
            "        ...,\n",
            "        [0.0367, 0.0375, 0.0374,  ..., 0.0072, 0.0233, 0.0385],\n",
            "        [0.0004, 0.0167, 0.0244,  ..., 0.0439, 0.0341, 0.0151],\n",
            "        [0.0254, 0.0059, 0.0468,  ..., 0.0223, 0.0112, 0.0421]])\n",
            "item_factors.weight tensor([[0.0415, 0.0100, 0.0095,  ..., 0.0470, 0.0245, 0.0083],\n",
            "        [0.0354, 0.0447, 0.0255,  ..., 0.0041, 0.0484, 0.0077],\n",
            "        [0.0144, 0.0420, 0.0099,  ..., 0.0066, 0.0262, 0.0276],\n",
            "        ...,\n",
            "        [0.0458, 0.0121, 0.0271,  ..., 0.0159, 0.0371, 0.0228],\n",
            "        [0.0343, 0.0395, 0.0290,  ..., 0.0203, 0.0265, 0.0372],\n",
            "        [0.0399, 0.0154, 0.0080,  ..., 0.0493, 0.0044, 0.0436]])\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 128\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"Is running on GPU:\", cuda)\n",
        "\n",
        "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
        "print(model)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "# GPU enable if you have a GPU...\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "# MSE loss\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# ADAM optimizier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Train data\n",
        "train_set = Loader()\n",
        "train_loader = DataLoader(train_set, 128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b71f23c4f6a4446a9c7992e9d43dc960",
            "ccd376fcb01c43bab839b24b78934363",
            "b5257ebade9a42f997528f05f1a2d87e",
            "f114ebbb8f9c41db8d2aeb499954ed11",
            "fe6de585bb854e598c6650876fef0dda",
            "bb1e1989427c4e36b6228186f4a4c2a2",
            "cf22746213b4495d8b6db97326033657",
            "d3ab64e98f6c4afba83f7c40cc632a41",
            "f705a55a7f9042728df1a047b4cc8ea5",
            "d27d1c08e0884eb9a9acef0b9b339f90",
            "5468d3251a104b0290dd2213062d0607"
          ]
        },
        "id": "v35ssHR3ngEj",
        "outputId": "d5345d67-e09a-444a-8c11-f1ddced79d34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b71f23c4f6a4446a9c7992e9d43dc960",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/128 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter #0 Loss: 0\n",
            "iter #1 Loss: 0\n",
            "iter #2 Loss: 0\n",
            "iter #3 Loss: 0\n",
            "iter #4 Loss: 0\n",
            "iter #5 Loss: 0\n",
            "iter #6 Loss: 0\n",
            "iter #7 Loss: 0\n",
            "iter #8 Loss: 0\n",
            "iter #9 Loss: 0\n",
            "iter #10 Loss: 0\n",
            "iter #11 Loss: 0\n",
            "iter #12 Loss: 0\n",
            "iter #13 Loss: 0\n",
            "iter #14 Loss: 0\n",
            "iter #15 Loss: 0\n",
            "iter #16 Loss: 0\n",
            "iter #17 Loss: 0\n",
            "iter #18 Loss: 0\n",
            "iter #19 Loss: 0\n",
            "iter #20 Loss: 0\n",
            "iter #21 Loss: 0\n",
            "iter #22 Loss: 0\n",
            "iter #23 Loss: 0\n",
            "iter #24 Loss: 0\n",
            "iter #25 Loss: 0\n",
            "iter #26 Loss: 0\n",
            "iter #27 Loss: 0\n",
            "iter #28 Loss: 0\n",
            "iter #29 Loss: 0\n",
            "iter #30 Loss: 0\n",
            "iter #31 Loss: 0\n",
            "iter #32 Loss: 0\n",
            "iter #33 Loss: 0\n",
            "iter #34 Loss: 0\n",
            "iter #35 Loss: 0\n",
            "iter #36 Loss: 0\n",
            "iter #37 Loss: 0\n",
            "iter #38 Loss: 0\n",
            "iter #39 Loss: 0\n",
            "iter #40 Loss: 0\n",
            "iter #41 Loss: 0\n",
            "iter #42 Loss: 0\n",
            "iter #43 Loss: 0\n",
            "iter #44 Loss: 0\n",
            "iter #45 Loss: 0\n",
            "iter #46 Loss: 0\n",
            "iter #47 Loss: 0\n",
            "iter #48 Loss: 0\n",
            "iter #49 Loss: 0\n",
            "iter #50 Loss: 0\n",
            "iter #51 Loss: 0\n",
            "iter #52 Loss: 0\n",
            "iter #53 Loss: 0\n",
            "iter #54 Loss: 0\n",
            "iter #55 Loss: 0\n",
            "iter #56 Loss: 0\n",
            "iter #57 Loss: 0\n",
            "iter #58 Loss: 0\n",
            "iter #59 Loss: 0\n",
            "iter #60 Loss: 0\n",
            "iter #61 Loss: 0\n",
            "iter #62 Loss: 0\n",
            "iter #63 Loss: 0\n",
            "iter #64 Loss: 0\n",
            "iter #65 Loss: 0\n",
            "iter #66 Loss: 0\n",
            "iter #67 Loss: 0\n",
            "iter #68 Loss: 0\n",
            "iter #69 Loss: 0\n",
            "iter #70 Loss: 0\n",
            "iter #71 Loss: 0\n",
            "iter #72 Loss: 0\n",
            "iter #73 Loss: 0\n",
            "iter #74 Loss: 0\n",
            "iter #75 Loss: 0\n",
            "iter #76 Loss: 0\n",
            "iter #77 Loss: 0\n",
            "iter #78 Loss: 0\n",
            "iter #79 Loss: 0\n",
            "iter #80 Loss: 0\n",
            "iter #81 Loss: 0\n",
            "iter #82 Loss: 0\n",
            "iter #83 Loss: 0\n",
            "iter #84 Loss: 0\n",
            "iter #85 Loss: 0\n",
            "iter #86 Loss: 0\n",
            "iter #87 Loss: 0\n",
            "iter #88 Loss: 0\n",
            "iter #89 Loss: 0\n",
            "iter #90 Loss: 0\n",
            "iter #91 Loss: 0\n",
            "iter #92 Loss: 0\n",
            "iter #93 Loss: 0\n",
            "iter #94 Loss: 0\n",
            "iter #95 Loss: 0\n",
            "iter #96 Loss: 0\n",
            "iter #97 Loss: 0\n",
            "iter #98 Loss: 0\n",
            "iter #99 Loss: 0\n",
            "iter #100 Loss: 0\n",
            "iter #101 Loss: 0\n",
            "iter #102 Loss: 0\n",
            "iter #103 Loss: 0\n",
            "iter #104 Loss: 0\n",
            "iter #105 Loss: 0\n",
            "iter #106 Loss: 0\n",
            "iter #107 Loss: 0\n",
            "iter #108 Loss: 0\n",
            "iter #109 Loss: 0\n",
            "iter #110 Loss: 0\n",
            "iter #111 Loss: 0\n",
            "iter #112 Loss: 0\n",
            "iter #113 Loss: 0\n",
            "iter #114 Loss: 0\n",
            "iter #115 Loss: 0\n",
            "iter #116 Loss: 0\n",
            "iter #117 Loss: 0\n",
            "iter #118 Loss: 0\n",
            "iter #119 Loss: 0\n",
            "iter #120 Loss: 0\n",
            "iter #121 Loss: 0\n",
            "iter #122 Loss: 0\n",
            "iter #123 Loss: 0\n",
            "iter #124 Loss: 0\n",
            "iter #125 Loss: 0\n",
            "iter #126 Loss: 0\n",
            "iter #127 Loss: 0\n"
          ]
        }
      ],
      "source": [
        "for it in tqdm(range(num_epochs)):\n",
        "    losses = []\n",
        "    for x, y in train_loader:\n",
        "         if cuda:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
        "            losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEs84BbBnh7r",
        "outputId": "d130d7c1-d4af-49cc-d5aa-a7133a8dd46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_factors.weight tensor([[0.0281, 0.0224, 0.0136,  ..., 0.0346, 0.0447, 0.0223],\n",
            "        [0.0025, 0.0376, 0.0024,  ..., 0.0321, 0.0203, 0.0120],\n",
            "        [0.0359, 0.0456, 0.0129,  ..., 0.0419, 0.0420, 0.0133],\n",
            "        ...,\n",
            "        [0.0367, 0.0375, 0.0374,  ..., 0.0072, 0.0233, 0.0385],\n",
            "        [0.0004, 0.0167, 0.0244,  ..., 0.0439, 0.0341, 0.0151],\n",
            "        [0.0254, 0.0059, 0.0468,  ..., 0.0223, 0.0112, 0.0421]])\n",
            "item_factors.weight tensor([[0.0415, 0.0100, 0.0095,  ..., 0.0470, 0.0245, 0.0083],\n",
            "        [0.0354, 0.0447, 0.0255,  ..., 0.0041, 0.0484, 0.0077],\n",
            "        [0.0144, 0.0420, 0.0099,  ..., 0.0066, 0.0262, 0.0276],\n",
            "        ...,\n",
            "        [0.0458, 0.0121, 0.0271,  ..., 0.0159, 0.0371, 0.0228],\n",
            "        [0.0343, 0.0395, 0.0290,  ..., 0.0203, 0.0265, 0.0372],\n",
            "        [0.0399, 0.0154, 0.0080,  ..., 0.0493, 0.0044, 0.0436]])\n"
          ]
        }
      ],
      "source": [
        "# By training the model, we will have tuned latent factors for movies and users.\n",
        "c = 0\n",
        "uw = 0\n",
        "iw = 0 \n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "        if c == 0:\n",
        "          uw = param.data\n",
        "          c +=1\n",
        "        else:\n",
        "          iw = param.data\n",
        "        #print('param_data', param_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8jhFlS_nkFM"
      },
      "outputs": [],
      "source": [
        "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TX8RiScnloz",
        "outputId": "9e585912-2e83-472c-d526-da5af2c41cbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9724"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trained_movie_embeddings) # unique movie factor weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZNz9w3hnm33"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "# Fit the clusters based on the movie weights\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VlSwU75nmyG",
        "outputId": "37fd4e5e-51a6-4820-f906-4a951f6d8985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster #0\n",
            "\t Terminator 2: Judgment Day (1991)\n",
            "\t Seven (a.k.a. Se7en) (1995)\n",
            "\t Back to the Future (1985)\n",
            "\t American History X (1998)\n",
            "\t Aliens (1986)\n",
            "\t Austin Powers: The Spy Who Shagged Me (1999)\n",
            "\t Ghost (1990)\n",
            "\t Bourne Identity, The (2002)\n",
            "\t Star Wars: Episode II - Attack of the Clones (2002)\n",
            "\t Mummy, The (1999)\n",
            "Cluster #1\n",
            "\t Star Wars: Episode IV - A New Hope (1977)\n",
            "\t Godfather, The (1972)\n",
            "\t Lord of the Rings: The Return of the King, The (2003)\n",
            "\t Aladdin (1992)\n",
            "\t Finding Nemo (2003)\n",
            "\t Indiana Jones and the Last Crusade (1989)\n",
            "\t Titanic (1997)\n",
            "\t Blade Runner (1982)\n",
            "\t Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "\t Willy Wonka & the Chocolate Factory (1971)\n",
            "Cluster #2\n",
            "\t Forrest Gump (1994)\n",
            "\t Matrix, The (1999)\n",
            "\t Shrek (2001)\n",
            "\t Dances with Wolves (1990)\n",
            "\t Die Hard (1988)\n",
            "\t Pretty Woman (1990)\n",
            "\t GoldenEye (1995)\n",
            "\t Goodfellas (1990)\n",
            "\t Truman Show, The (1998)\n",
            "\t Jumanji (1995)\n",
            "Cluster #3\n",
            "\t Fight Club (1999)\n",
            "\t Mission: Impossible (1996)\n",
            "\t Die Hard: With a Vengeance (1995)\n",
            "\t Inception (2010)\n",
            "\t Batman Forever (1995)\n",
            "\t One Flew Over the Cuckoo's Nest (1975)\n",
            "\t Ghostbusters (a.k.a. Ghost Busters) (1984)\n",
            "\t Batman Begins (2005)\n",
            "\t Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)\n",
            "\t Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
            "Cluster #4\n",
            "\t Schindler's List (1993)\n",
            "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
            "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
            "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
            "\t Lord of the Rings: The Two Towers, The (2002)\n",
            "\t Memento (2000)\n",
            "\t Beauty and the Beast (1991)\n",
            "\t Good Will Hunting (1997)\n",
            "\t Kill Bill: Vol. 1 (2003)\n",
            "\t Clockwork Orange, A (1971)\n",
            "Cluster #5\n",
            "\t Usual Suspects, The (1995)\n",
            "\t American Beauty (1999)\n",
            "\t Fugitive, The (1993)\n",
            "\t Fargo (1996)\n",
            "\t Ace Ventura: Pet Detective (1994)\n",
            "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
            "\t Monsters, Inc. (2001)\n",
            "\t Godfather: Part II, The (1974)\n",
            "\t Net, The (1995)\n",
            "\t Kill Bill: Vol. 2 (2004)\n",
            "Cluster #6\n",
            "\t Shawshank Redemption, The (1994)\n",
            "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
            "\t Speed (1994)\n",
            "\t Gladiator (2000)\n",
            "\t Men in Black (a.k.a. MIB) (1997)\n",
            "\t Mask, The (1994)\n",
            "\t Dark Knight, The (2008)\n",
            "\t X-Men (2000)\n",
            "\t Terminator, The (1984)\n",
            "\t Eternal Sunshine of the Spotless Mind (2004)\n",
            "Cluster #7\n",
            "\t Pulp Fiction (1994)\n",
            "\t Toy Story (1995)\n",
            "\t Apollo 13 (1995)\n",
            "\t Batman (1989)\n",
            "\t Saving Private Ryan (1998)\n",
            "\t Mrs. Doubtfire (1993)\n",
            "\t Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n",
            "\t Twister (1996)\n",
            "\t Spider-Man (2002)\n",
            "\t Catch Me If You Can (2002)\n",
            "Cluster #8\n",
            "\t Silence of the Lambs, The (1991)\n",
            "\t Jurassic Park (1993)\n",
            "\t Braveheart (1995)\n",
            "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
            "\t True Lies (1994)\n",
            "\t Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "\t Alien (1979)\n",
            "\t Princess Bride, The (1987)\n",
            "\t Babe (1995)\n",
            "\t Incredibles, The (2004)\n",
            "Cluster #9\n",
            "\t Independence Day (a.k.a. ID4) (1996)\n",
            "\t Sixth Sense, The (1999)\n",
            "\t Lion King, The (1994)\n",
            "\t Groundhog Day (1993)\n",
            "\t Stargate (1994)\n",
            "\t Monty Python and the Holy Grail (1975)\n",
            "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
            "\t Reservoir Dogs (1992)\n",
            "\t E.T. the Extra-Terrestrial (1982)\n",
            "\t Minority Report (2002)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "'''It can be seen here that the movies that are in the same cluster tend to have\n",
        "similar genres. Also note that the algorithm is unfamiliar with the movie name\n",
        "and only obtained the relationships by looking at the numbers representing how\n",
        "users have responded to the movie selections.'''\n",
        "for cluster in range(10):\n",
        "  print(\"Cluster #{}\".format(cluster))\n",
        "  movs = []\n",
        "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
        "    movid = train_set.idx2movieid[movidx]\n",
        "    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n",
        "    movs.append((movie_names[movid], rat_count))\n",
        "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
        "    print(\"\\t\", mov[0])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "04c2774e0eee72fdf7c569530da90ed42b07f746012a791613028ba7115aa244"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5468d3251a104b0290dd2213062d0607": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5257ebade9a42f997528f05f1a2d87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3ab64e98f6c4afba83f7c40cc632a41",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f705a55a7f9042728df1a047b4cc8ea5",
            "value": 128
          }
        },
        "b71f23c4f6a4446a9c7992e9d43dc960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd376fcb01c43bab839b24b78934363",
              "IPY_MODEL_b5257ebade9a42f997528f05f1a2d87e",
              "IPY_MODEL_f114ebbb8f9c41db8d2aeb499954ed11"
            ],
            "layout": "IPY_MODEL_fe6de585bb854e598c6650876fef0dda"
          }
        },
        "bb1e1989427c4e36b6228186f4a4c2a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd376fcb01c43bab839b24b78934363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb1e1989427c4e36b6228186f4a4c2a2",
            "placeholder": "​",
            "style": "IPY_MODEL_cf22746213b4495d8b6db97326033657",
            "value": "100%"
          }
        },
        "cf22746213b4495d8b6db97326033657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d27d1c08e0884eb9a9acef0b9b339f90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ab64e98f6c4afba83f7c40cc632a41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f114ebbb8f9c41db8d2aeb499954ed11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d27d1c08e0884eb9a9acef0b9b339f90",
            "placeholder": "​",
            "style": "IPY_MODEL_5468d3251a104b0290dd2213062d0607",
            "value": " 128/128 [01:05&lt;00:00,  1.96it/s]"
          }
        },
        "f705a55a7f9042728df1a047b4cc8ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe6de585bb854e598c6650876fef0dda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
